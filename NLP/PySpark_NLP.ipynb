{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySpark_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmqyA3baQFEd"
      },
      "source": [
        "## Problem\n",
        "\n",
        "Predict spam or ham."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HljnsOK0OhQS",
        "outputId": "265f4171-16c8-4992-ad6c-e6a64bdfe8c1"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4 MB 61 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 50.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=1a4a19b12b900c8710e0c4c2dabab8707e6a2b1b1b7ee15d751ce3609ccb447f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "5H62uOdJQVsK",
        "outputId": "5fd8f317-99f4-410f-e202-a7166579e51a"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('nlp').getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "sc"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://8e0bd4cfde44:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>nlp</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ],
            "text/plain": [
              "<SparkContext master=local[*] appName=nlp>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NA8hTGHpQ4Kq",
        "outputId": "1e9a7d4c-6659-406f-e58c-c4e7ce9fd4ac"
      },
      "source": [
        "df = spark.read.csv('SMSSpamCollection', inferSchema = True, sep='\\t')\n",
        "df.printSchema()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _c0: string (nullable = true)\n",
            " |-- _c1: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7eTopJpRlwM",
        "outputId": "8ad25b3e-f44d-4727-823a-3b5101d834ec"
      },
      "source": [
        "df.show(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------------+\n",
            "| _c0|                 _c1|\n",
            "+----+--------------------+\n",
            "| ham|Go until jurong p...|\n",
            "| ham|Ok lar... Joking ...|\n",
            "|spam|Free entry in 2 a...|\n",
            "| ham|U dun say so earl...|\n",
            "| ham|Nah I don't think...|\n",
            "|spam|FreeMsg Hey there...|\n",
            "| ham|Even my brother i...|\n",
            "| ham|As per your reque...|\n",
            "|spam|WINNER!! As a val...|\n",
            "|spam|Had your mobile 1...|\n",
            "+----+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZMuFhN5RpIe",
        "outputId": "8031dfe9-6c09-486b-c93a-31801274ff29"
      },
      "source": [
        "df.describe().show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+--------------------+\n",
            "|summary| _c0|                 _c1|\n",
            "+-------+----+--------------------+\n",
            "|  count|5574|                5574|\n",
            "|   mean|null|               645.0|\n",
            "| stddev|null|                null|\n",
            "|    min| ham| &lt;#&gt;  in mc...|\n",
            "|    max|spam|… we r stayin her...|\n",
            "+-------+----+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lKWJiWd5FpF"
      },
      "source": [
        "df = df.withColumnRenamed('_c0','class').withColumnRenamed('_c1','text')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PB-RMUd5R5Ft",
        "outputId": "d45c1a00-faa5-4dc6-b39a-503de4cbe39a"
      },
      "source": [
        "df.groupBy('class').count().show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|class|count|\n",
            "+-----+-----+\n",
            "|  ham| 4827|\n",
            "| spam|  747|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "AD55Mrs_3d5J"
      },
      "source": [
        "from pyspark.sql.functions import length"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c881JaM03d5L"
      },
      "source": [
        "df = df.withColumn('length', length(df['text']))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBo8x2hu3d5N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39ec38f1-1091-4b2b-8769-bccc4581bb34"
      },
      "source": [
        "df.show(5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+------+\n",
            "|class|                text|length|\n",
            "+-----+--------------------+------+\n",
            "|  ham|Go until jurong p...|   111|\n",
            "|  ham|Ok lar... Joking ...|    29|\n",
            "| spam|Free entry in 2 a...|   155|\n",
            "|  ham|U dun say so earl...|    49|\n",
            "|  ham|Nah I don't think...|    61|\n",
            "+-----+--------------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rH15m64t3d5N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15ef96a2-4948-4c3f-8d37-486c63ac2122"
      },
      "source": [
        "df.groupby('class').mean().show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------+\n",
            "|class|      avg(length)|\n",
            "+-----+-----------------+\n",
            "|  ham|71.45431945307645|\n",
            "| spam|138.6706827309237|\n",
            "+-----+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzfEIOpf5iYJ"
      },
      "source": [
        "from pyspark.ml.feature import Tokenizer,StopWordsRemover, CountVectorizer,IDF,StringIndexer\n",
        "\n",
        "tokenizer = Tokenizer(inputCol='text', outputCol='token_text')\n",
        "stopremove = StopWordsRemover(inputCol='token_text', outputCol='stop_tokens')\n",
        "count_vec = CountVectorizer(inputCol='stop_tokens', outputCol='c_vec')\n",
        "idf = IDF(inputCol='c_vec', outputCol='tf_idf')\n",
        "ham_spam_to_num = StringIndexer(inputCol='class', outputCol='label')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdrZt0lM5ikv"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "clean_up = VectorAssembler(inputCols=['tf_idf', 'length'], outputCol='features')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "PLkQjm403d5U"
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "\n",
        "data_prep_pipe = Pipeline(stages = [ham_spam_to_num, tokenizer, stopremove, count_vec, idf, clean_up])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r559nXbk3d5U"
      },
      "source": [
        "cleaner = data_prep_pipe.fit(df)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Udk1avld3d5V"
      },
      "source": [
        "clean_data = cleaner.transform(df)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2gpw4bx6gvF",
        "outputId": "ff94648c-8272-49d5-e5c9-c6fea98f49f8"
      },
      "source": [
        "clean_data.show(5)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|class|                text|length|label|          token_text|         stop_tokens|               c_vec|              tf_idf|            features|\n",
            "+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|  ham|Go until jurong p...|   111|  0.0|[go, until, juron...|[go, jurong, poin...|(13423,[7,11,31,6...|(13423,[7,11,31,6...|(13424,[7,11,31,6...|\n",
            "|  ham|Ok lar... Joking ...|    29|  0.0|[ok, lar..., joki...|[ok, lar..., joki...|(13423,[0,24,297,...|(13423,[0,24,297,...|(13424,[0,24,297,...|\n",
            "| spam|Free entry in 2 a...|   155|  1.0|[free, entry, in,...|[free, entry, 2, ...|(13423,[2,13,19,3...|(13423,[2,13,19,3...|(13424,[2,13,19,3...|\n",
            "|  ham|U dun say so earl...|    49|  0.0|[u, dun, say, so,...|[u, dun, say, ear...|(13423,[0,70,80,1...|(13423,[0,70,80,1...|(13424,[0,70,80,1...|\n",
            "|  ham|Nah I don't think...|    61|  0.0|[nah, i, don't, t...|[nah, think, goes...|(13423,[36,134,31...|(13423,[36,134,31...|(13424,[36,134,31...|\n",
            "+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuoFnXe864gU",
        "outputId": "4d8e68e4-797c-41fe-927e-822a70d5c85c"
      },
      "source": [
        "clean_data.head(3)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(class='ham', text='Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', length=111, label=0.0, token_text=['go', 'until', 'jurong', 'point,', 'crazy..', 'available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet...', 'cine', 'there', 'got', 'amore', 'wat...'], stop_tokens=['go', 'jurong', 'point,', 'crazy..', 'available', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet...', 'cine', 'got', 'amore', 'wat...'], c_vec=SparseVector(13423, {7: 1.0, 11: 1.0, 31: 1.0, 61: 1.0, 72: 1.0, 344: 1.0, 625: 1.0, 731: 1.0, 1409: 1.0, 1598: 1.0, 4485: 1.0, 6440: 1.0, 8092: 1.0, 8838: 1.0, 11344: 1.0, 12979: 1.0}), tf_idf=SparseVector(13423, {7: 3.1126, 11: 3.2055, 31: 3.822, 61: 4.2072, 72: 4.322, 344: 5.4072, 625: 5.918, 731: 6.1411, 1409: 6.6801, 1598: 6.8343, 4485: 7.5274, 6440: 7.9329, 8092: 7.9329, 8838: 7.9329, 11344: 7.9329, 12979: 7.9329}), features=SparseVector(13424, {7: 3.1126, 11: 3.2055, 31: 3.822, 61: 4.2072, 72: 4.322, 344: 5.4072, 625: 5.918, 731: 6.1411, 1409: 6.6801, 1598: 6.8343, 4485: 7.5274, 6440: 7.9329, 8092: 7.9329, 8838: 7.9329, 11344: 7.9329, 12979: 7.9329, 13423: 111.0})),\n",
              " Row(class='ham', text='Ok lar... Joking wif u oni...', length=29, label=0.0, token_text=['ok', 'lar...', 'joking', 'wif', 'u', 'oni...'], stop_tokens=['ok', 'lar...', 'joking', 'wif', 'u', 'oni...'], c_vec=SparseVector(13423, {0: 1.0, 24: 1.0, 297: 1.0, 457: 1.0, 2601: 1.0, 3605: 1.0}), tf_idf=SparseVector(13423, {0: 2.0167, 24: 3.5762, 297: 5.3302, 457: 5.7357, 2601: 7.2398, 3605: 7.5274}), features=SparseVector(13424, {0: 2.0167, 24: 3.5762, 297: 5.3302, 457: 5.7357, 2601: 7.2398, 3605: 7.5274, 13423: 29.0})),\n",
              " Row(class='spam', text=\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\", length=155, label=1.0, token_text=['free', 'entry', 'in', '2', 'a', 'wkly', 'comp', 'to', 'win', 'fa', 'cup', 'final', 'tkts', '21st', 'may', '2005.', 'text', 'fa', 'to', '87121', 'to', 'receive', 'entry', 'question(std', 'txt', \"rate)t&c's\", 'apply', \"08452810075over18's\"], stop_tokens=['free', 'entry', '2', 'wkly', 'comp', 'win', 'fa', 'cup', 'final', 'tkts', '21st', 'may', '2005.', 'text', 'fa', '87121', 'receive', 'entry', 'question(std', 'txt', \"rate)t&c's\", 'apply', \"08452810075over18's\"], c_vec=SparseVector(13423, {2: 1.0, 13: 1.0, 19: 1.0, 30: 1.0, 89: 1.0, 154: 1.0, 193: 1.0, 305: 2.0, 458: 1.0, 515: 1.0, 631: 1.0, 855: 1.0, 954: 1.0, 1916: 1.0, 2010: 1.0, 2356: 2.0, 3023: 1.0, 3287: 1.0, 3442: 1.0, 5016: 1.0, 5200: 1.0}), tf_idf=SparseVector(13423, {2: 2.7045, 13: 3.3327, 19: 3.5635, 30: 3.6702, 89: 4.4214, 154: 4.8419, 193: 5.0997, 305: 11.07, 458: 5.6816, 515: 5.7357, 631: 5.918, 855: 6.2282, 954: 6.3235, 1916: 7.0166, 2010: 7.0166, 2356: 15.0549, 3023: 7.2398, 3287: 7.2398, 3442: 7.5274, 5016: 7.5274, 5200: 7.5274}), features=SparseVector(13424, {2: 2.7045, 13: 3.3327, 19: 3.5635, 30: 3.6702, 89: 4.4214, 154: 4.8419, 193: 5.0997, 305: 11.07, 458: 5.6816, 515: 5.7357, 631: 5.918, 855: 6.2282, 954: 6.3235, 1916: 7.0166, 2010: 7.0166, 2356: 15.0549, 3023: 7.2398, 3287: 7.2398, 3442: 7.5274, 5016: 7.5274, 5200: 7.5274, 13423: 155.0}))]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Vw-D3Hf6tar",
        "outputId": "b23c1edd-556e-4090-ed68-0edaf2f22e49"
      },
      "source": [
        "clean_data = clean_data.select(['label','features'])\n",
        "clean_data.show(5)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|  0.0|(13424,[7,11,31,6...|\n",
            "|  0.0|(13424,[0,24,297,...|\n",
            "|  1.0|(13424,[2,13,19,3...|\n",
            "|  0.0|(13424,[0,70,80,1...|\n",
            "|  0.0|(13424,[36,134,31...|\n",
            "+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0sucsViR92W",
        "outputId": "fad78fee-802d-44b7-e9e2-77f03b1cd418"
      },
      "source": [
        "train_data, test_data  = clean_data.randomSplit([0.8, 0.2], 20)\n",
        "\n",
        "print(\"Records for training: \" + str(train_data.count()))\n",
        "print(\"Records for evaluation: \" + str(test_data.count()))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Records for training: 4492\n",
            "Records for evaluation: 1082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_f69arJ7nHw",
        "outputId": "b3f34566-d5d4-4bf9-af3f-ff892c4cc6ed"
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- class: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- length: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6eTnaje7r6d",
        "outputId": "503947ff-3208-4b1f-b29c-a7c674197c97"
      },
      "source": [
        "clean_data.printSchema()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- label: double (nullable = false)\n",
            " |-- features: vector (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO6BSHcn53Xv"
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "\n",
        "nb = NaiveBayes()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YnPoKl57Vvc"
      },
      "source": [
        "model = nb.fit(train_data)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZgQm9SA7VyQ"
      },
      "source": [
        "test_results = model.transform(test_data)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hR27u_RF73Pu",
        "outputId": "fa06d627-5d3b-4196-9c3c-0168416bb0b2"
      },
      "source": [
        "test_results.show(10)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+--------------------+--------------------+----------+\n",
            "|label|            features|       rawPrediction|         probability|prediction|\n",
            "+-----+--------------------+--------------------+--------------------+----------+\n",
            "|  0.0|(13424,[0,1,2,41,...|[-1072.0776881935...|[1.0,7.2108832156...|       0.0|\n",
            "|  0.0|(13424,[0,1,9,14,...|[-543.83599050000...|[1.0,5.5318075823...|       0.0|\n",
            "|  0.0|(13424,[0,1,14,78...|[-689.63164356196...|[1.0,3.4213121092...|       0.0|\n",
            "|  0.0|(13424,[0,1,15,20...|[-669.18490790247...|[1.0,1.4000965626...|       0.0|\n",
            "|  0.0|(13424,[0,1,27,88...|[-1539.4993336851...|[8.18107202084444...|       1.0|\n",
            "|  0.0|(13424,[0,1,72,10...|[-676.98193296836...|[1.0,8.5532364756...|       0.0|\n",
            "|  0.0|(13424,[0,2,3,6,9...|[-3434.3436727419...|[1.0,7.1159145010...|       0.0|\n",
            "|  0.0|(13424,[0,2,3,6,9...|[-3434.3436727419...|[1.0,7.1159145010...|       0.0|\n",
            "|  0.0|(13424,[0,2,4,5,7...|[-988.48665838165...|[1.0,2.9910950726...|       0.0|\n",
            "|  0.0|(13424,[0,2,4,5,1...|[-2507.9235088697...|[1.0,2.8937080763...|       0.0|\n",
            "+-----+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KwKB9u387Yz",
        "outputId": "b8d2f5f9-ae1f-4e68-8f29-b371f54af5fe"
      },
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "print('Accuracy:', acc_eval.evaluate(test_results))\n",
        "\n",
        "lrmetrics = MulticlassMetrics(test_results['label','prediction'].rdd)\n",
        "print('Confusion Matrix:\\n', lrmetrics.confusionMatrix())\n",
        "print('F1 Score:', lrmetrics.fMeasure(1.0, 1.0))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9183280766190828\n",
            "Confusion Matrix:\n",
            " DenseMatrix([[832.,   2.],\n",
            "             [ 95., 153.]])\n",
            "F1 Score: 0.7593052109181141\n"
          ]
        }
      ]
    }
  ]
}